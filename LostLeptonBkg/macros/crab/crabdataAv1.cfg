[CRAB]

jobtype     = cmssw

# sge for naf, glite else	
#scheduler   = glite
# scheduler sagt wo der job laufen solll sge steht fuer naf hamburg
scheduler   = sge 

#server_name = pisa
#use_server = 1


[CMSSW]

dbs_url=https://cmsdbsprod.cern.ch:8443/cms_dbs_ph_analysis_02_writer/servlet/DBSServlet
datasetpath = /HT/mschrode-RA2PreSelection_Run2012A-13Jul2012-v1_V4-21a074f94cdbe7cfbeeb19be46b40a6a/USER

pset = /afs/desy.de/user/a/adraeger/xxl/code/CMSSW_5_3_5/src/RA2Classic/LostLeptonBkg/test/llEff_test_cfg.py
#total_number_of_events = 1000
##total_number_of_events = 1000
### Number of events to be processed per job
##events_per_job = 1000
#number_of_jobs = 1
##100

pycfg_params           = global_tag=FT_53_V6C_AN3::All

## for real data use this block
lumi_mask = Cert_190456-208686_ABCD.txt


total_number_of_lumis = -1
lumis_per_job = 200
## sagt wieviele lumis pro rechenauftrag zusammengefasst werden
#lumis_per_job =500
#lumis_per_job =250
#lumis_per_job =100


### The output files produced by your application (comma separated list)
               
output_file = LostLeptonEffFromMC.root

[USER]
thresholdLevel = 50
ui_working_dir= data_a_v1






cpu=2:00:00
return_data = 1

# 0: sandbox, 1: dcache
copy_data   = 0

storage_element  = T2_DE_DESY
user_remote_dir  = Skims_Summer11_
#ui_working_dir   = Summer09_QCD_Pt30


#publish_data_name= RA2_We_Pythia_Z2_V4

dbs_url_for_publication=https://cmsdbsprod.cern.ch:8443/cms_dbs_ph_analysis_02_writer/servlet/DBSServlet

publish_data = 0

[GRID]

# LCG middleware version installed on testbed
lcg_version = 2

## CMS myproxy server, to proxy delegation
proxy_server  = myproxy.cern.ch 
#proxy_server = grid-pxy.desy.de

## Group in VOMS
group = dcms

se_white_list = desy.de
## fields written into jdl
virtual_organization = cms

## number or retry count
retry_count = 2
[SGE]
#angabe wie gross die files sind.. und cpu usage in stunden
resource = -V -l h_vmem=2G -l h_cpu=3:0:0 -l site=hh  
#resource = -V -l h_vmem=2G -l h_cpu=24:0:0 -l site=hh  
#-M thomsen@cern.ch -m a
#ae

